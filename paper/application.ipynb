{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "# To get the absolute path of the directory where the lgdcnn module is located\n",
    "lgdcnn_dir = r\"D:\\deep\\LGDCNN\"\n",
    "# Add the directory where the lgdcnn module is located to the module search path\n",
    "sys.path.append(lgdcnn_dir)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lgdcnn.fusion_lstm_dcnn import LGDCNN\n",
    "# from lgdcnn.fusion_lstm_dcnn_v1 import LGDCNN\n",
    "# from crabnet.model_application import Model\n",
    "from lgdcnn.train import Model\n",
    "from lgdcnn.utils.get_compute_device import get_compute_device\n",
    "\n",
    "compute_device = get_compute_device(prefer_last=True)\n",
    "RNG_SEED = 42\n",
    "torch.manual_seed(RNG_SEED)  \n",
    "np.random.seed(RNG_SEED)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "lgdcnn_dir = r\"D:\\deep\\LGDCNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: ['aflow__ael_bulk_modulus_vrh', 'aflow__ael_debye_temperature', 'aflow__ael_shear_modulus_vrh', 'aflow__agl_thermal_conductivity_300K', 'aflow__agl_thermal_expansion_300K', 'aflow__Egap', 'aflow__energy_atom', 'CritExam__Ed', 'CritExam__Ef', 'mp_bulk_modulus', 'mp_elastic_anisotropy', 'mp_e_hull', 'mp_mu_b', 'mp_shear_modulus', 'OQMD_Bandgap', 'OQMD_Energy_per_atom', 'OQMD_Formation_Enthalpy', 'OQMD_Volume_per_atom']\n",
      "property: aflow__ael_bulk_modulus_vrh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 3428/3428 [00:00<00:00, 219613.17formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with batchsize 256 (2**8.000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating EDM: 100%|██████████| 732/732 [00:00<00:00, 243978.90formulae/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stepping every 140 training passes, cycling lr every 10 epochs\n",
      "checkin at 20 epochs to match lr scheduler\n",
      "Epoch: 0/300 --- train mae: 53 val mae: 54\n",
      "Epoch: 19/300 --- train mae: 10.9 val mae: 13.8\n"
     ]
    }
   ],
   "source": [
    "def get_model(Fork,model_name, mat_prop, classification=False, batch_size=None,\n",
    "              transfer=None, verbose=True):\n",
    "    # Get the TorchedCrabNet architecture loaded\n",
    "    model = Model(Fork(compute_device=compute_device).to(compute_device),\n",
    "                  model_name=f'{mat_prop}', verbose=verbose)\n",
    "\n",
    "    # Train network starting at pretrained weights\n",
    "    if transfer is not None:\n",
    "        model.load_network(f'{transfer}.pth')\n",
    "        model.model_name = f'{mat_prop}'\n",
    "\n",
    "    # Apply BCEWithLogitsLoss to model output if binary classification is True\n",
    "    if classification:\n",
    "        model.classification = True\n",
    "\n",
    "    # Get the datafiles you will learn from\n",
    "    train_data = os.path.join(lgdcnn_dir,\"data\", \"benchmark_data\", mat_prop, 'train.csv') \n",
    "    val_data = os.path.join(lgdcnn_dir,\"data\", \"benchmark_data\", mat_prop, 'val.csv')\n",
    "\n",
    "    # Load the train and validation data before fitting the network\n",
    "    data_size = pd.read_csv(train_data).shape[0]\n",
    "    batch_size = 2**round(np.log2(data_size)-4)\n",
    "    if batch_size < 2**7:\n",
    "        batch_size = 2**7\n",
    "    if batch_size > 2**12:\n",
    "        batch_size = 2**12\n",
    "    # batch_size = 2**7\n",
    "    model.load_data(train_data, batch_size=batch_size, train=True)\n",
    "    print(f'training with batchsize {model.batch_size} '\n",
    "          f'(2**{np.log2(model.batch_size):0.3f})')\n",
    "    model.load_data(val_data, batch_size=batch_size)\n",
    "\n",
    "    # Set the number of epochs, decide if you want a loss curve to be plotted\n",
    "    model.fit(epochs=300, losscurve=False)\n",
    "\n",
    "    # Save the network (saved as f\"{model_name}.pth\")\n",
    "    model.save_network(model_name)\n",
    "    return model\n",
    "\n",
    "\n",
    "def to_csv(output, save_name):\n",
    "    # parse output and save to csv\n",
    "    act, pred, formulae, uncertainty = output\n",
    "    df = pd.DataFrame([formulae, act, pred, uncertainty]).T\n",
    "    df.columns = ['formula', 'actual', 'predicted', 'uncertainty']\n",
    "    save_path = os.path.join(lgdcnn_dir,\"results\", \"Benchmark\") \n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    df.to_csv(f'{save_path}/{save_name}', index_label='Index')\n",
    "\n",
    "\n",
    "def load_model(Fork, lgdcnn_dir, model_name, mat_prop, classification, file_name, verbose=True):\n",
    "    # Load up a saved network.\n",
    "    model = Model(Fork(compute_device=compute_device).to(compute_device),\n",
    "                  model_name=f'{mat_prop}', verbose=verbose)\n",
    "    model.load_network(model_name, f'{mat_prop}.pth') # multi_lstm_attention_residual_dpcnn_V8_512\n",
    "\n",
    "    # Check if classifcation task\n",
    "    if classification:\n",
    "        model.classification = True\n",
    "\n",
    "    # Load the data you want to predict with\n",
    "    data = os.path.join(lgdcnn_dir,\"data\",\"benchmark_data\",mat_prop,file_name)\n",
    "    # data is reloaded to model.data_loader\n",
    "    model.load_data(data, batch_size=2**9, train=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_results(model):\n",
    "    output = model.predict(model.data_loader)  # predict the data saved here\n",
    "    return model, output\n",
    "\n",
    "\n",
    "def save_results(Fork,lgdcnn_dir, model_name, mat_prop, classification, file_name, verbose=True):\n",
    "    model = load_model(Fork, lgdcnn_dir, model_name, mat_prop, classification, file_name, verbose=verbose)\n",
    "    model, output = get_results(model)\n",
    "\n",
    "    # Get appropriate metrics for saving to csv\n",
    "    if model.classification:\n",
    "        auc = roc_auc_score(output[0], output[1])\n",
    "        print(f'\\n{mat_prop} ROC AUC: {auc:0.4f}')\n",
    "    else:\n",
    "        mae = np.abs(output[0] - output[1]).mean()\n",
    "        print(f'\\n{mat_prop} mae: {mae:0.4g}')\n",
    "        \n",
    "     # save predictions to a csv\n",
    "    fname = f'{mat_prop}_{file_name.replace(\".csv\", \"\")}_output.csv'\n",
    "    to_csv(output, fname)\n",
    "    return model, mae\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_name = \"L-G-DCNN-TEST\"\n",
    "    Fork = LGDCNN\n",
    "    # Get data to benchmark on\n",
    "    # data_dir = 'data/benchmark_data'\n",
    "    benchmark_data_dir = os.path.join(lgdcnn_dir,\"data\",\"benchmark_data\")\n",
    "    mat_props = os.listdir(benchmark_data_dir)\n",
    "    classification_list = []\n",
    "    print(f'training: {mat_props}')\n",
    "    for mat_prop in mat_props:\n",
    "        classification = False\n",
    "        if mat_prop in classification_list:\n",
    "            classification = True\n",
    "        print(f'property: {mat_prop}')\n",
    "        model = get_model(Fork,model_name, mat_prop, classification, verbose=True)\n",
    "        print('=====================================================')\n",
    "        print('calculating test mae')\n",
    "        model_test, t_mae = save_results(lgdcnn_dir,model_name, mat_prop, classification,\n",
    "                                         'test.csv', verbose=False)\n",
    "        print('calculating val mae')\n",
    "        model_val, v_mae = save_results(lgdcnn_dir, model_name, mat_prop, classification,\n",
    "                                        'val.csv', verbose=False)\n",
    "        print('=====================================================')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### application for Element contribution to property prediction as a function of composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: ['matbench_mp_gap3']\n",
      "property: matbench_mp_gap3\n",
      "=====================================================\n",
      "=====================================================\n",
      "calculating test mae\n",
      "loading data with up to 2 elements in the formula\n",
      "\n",
      "matbench_mp_gap3 mae: 0.226\n",
      "63\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "# application 没有get_model就是没有train的过程\n",
    "\n",
    "def load_model(mat_prop, classification, file_name, verbose=True):\n",
    "    # Load up a saved network.\n",
    "    model = Model(LGDCNN(compute_device=compute_device).to(compute_device),\n",
    "                  model_name=f'{mat_prop}', verbose=verbose)\n",
    "    model.load_network(f'{mat_prop}.pth') # multi_lstm_attention_residual_dpcnn_V8_512\n",
    "\n",
    "    # Check if classifcation task\n",
    "    if classification:\n",
    "        model.classification = True\n",
    "\n",
    "    # mat_prop1 = 'MP_e_form'\n",
    "    mat_prop1 = 'Mp_gap'\n",
    "    # mat_prop1 = 'MP'\n",
    "    # mat_prop1 = 'MP_e_above_hull'\n",
    "    # mat_prop1 = 'MP_magnetism'\n",
    "    # mat_prop ='MP_dielectric'\n",
    "    # mat_prop1 = 'MP_Bulk_Modulus'\n",
    "    # mat_prop1 = 'MP_Shear_Modulus'\n",
    "    \n",
    "    # mat_prop1 = 'OQMD_Formation_Enthalpy'\n",
    "    # Load the data you want to predict with\n",
    "    data = f'data/application/{mat_prop1}/{file_name}'\n",
    "    # data is reloaded to model.data_loader\n",
    "    model.load_data(data, batch_size=2**9, train=False)\n",
    "    return model\n",
    "\n",
    "def to_csv(output, save_name):\n",
    "    # parse output and save to csv\n",
    "    act, pred, formulae, uncertainty = output\n",
    "    print(len(formulae))\n",
    "    df = pd.DataFrame([formulae,act, pred,uncertainty]).T\n",
    "    df.columns = [ 'formula','actual', 'predicted', 'uncertainty']\n",
    "    save_path = 'data/application/prediction'\n",
    "    # save_path = 'publication_predictions/onehot_matbench__predictions'\n",
    "    # save_path = 'publication_predictions/random_200_matbench__predictions'\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    df.to_csv(f'{save_path}/{save_name}', index_label='Index')\n",
    "\n",
    "\n",
    "def get_results(model):\n",
    "    output = model.predict(model.data_loader)  # predict the data saved here\n",
    "    return model, output\n",
    "\n",
    "\n",
    "def save_results(mat_prop, classification, file_name, verbose=True):\n",
    "    model = load_model(mat_prop, classification, file_name, verbose=verbose)\n",
    "    model, output = get_results(model)\n",
    "\n",
    "    # Get appropriate metrics for saving to csv\n",
    "    if model.classification:\n",
    "        auc = roc_auc_score(output[0], output[1])\n",
    "        print(f'\\n{mat_prop} ROC AUC: {auc:0.3f}')\n",
    "    else:\n",
    "        mae = np.abs(output[0] - output[1]).mean()\n",
    "        print(f'\\n{mat_prop} mae: {mae:0.3g}')\n",
    "\n",
    "    # save predictions to a csv\n",
    "    fname = f'{mat_prop}_{file_name.replace(\".csv\", \"\")}_crabnet.csv'\n",
    "    to_csv(output, fname)\n",
    "    return model, mae\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # data_dir = 'data/benchmark_data'\n",
    "    # mat_props = os.listdir(data_dir)\n",
    "    classification_list = []\n",
    "    \n",
    "    # mat_props =  [ 'matbench_mp_gap4', 'mp_bulk_modulus', 'mp_elastic_anisotropy', 'mp_e_hull', \n",
    "    # 'mp_mu_b', 'mp_shear_modulus','matbench_mp_e_form0']\n",
    "    # mat_props = ['OQMD_Formation_Enthalpy']\n",
    "    \n",
    "\n",
    "    mat_props = ['matbench_mp_gap3']\n",
    "    # mat_props = ['MP_Formation_Enthalpy']\n",
    "    print(f'training: {mat_props}')\n",
    "    for mat_prop in mat_props:\n",
    "        classification = False\n",
    "        if mat_prop in classification_list:\n",
    "            classification = True\n",
    "        print(f'property: {mat_prop}')\n",
    "        # model = get_model(mat_prop, classification, verbose=True)\n",
    "\n",
    "        print('=====================================================')\n",
    "        # print('calculating train mae')\n",
    "        # model_train, mae_train = save_results( mat_prop, classification,\n",
    "                                        #   'train.csv', verbose=False)\n",
    "        print('=====================================================')\n",
    "        print('calculating test mae')\n",
    "        model_test, t_mae = save_results(mat_prop, classification,\n",
    "                                        'cu_O_mp_gap.csv', verbose=False)\n",
    "        # print('calculating val mae')\n",
    "        # model_val, v_mae = save_results(mat_prop, classification,\n",
    "                                        # 'val.csv', verbose=False)\n",
    "        print('=====================================================')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test LGDCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: ['aflow__ael_bulk_modulus_vrh', 'aflow__ael_debye_temperature', 'aflow__ael_shear_modulus_vrh', 'aflow__agl_thermal_conductivity_300K', 'aflow__agl_thermal_expansion_300K', 'aflow__Egap', 'aflow__energy_atom', 'CritExam__Ed', 'CritExam__Ef', 'mp_bulk_modulus', 'mp_elastic_anisotropy', 'mp_e_hull', 'mp_mu_b', 'mp_shear_modulus', 'OQMD_Bandgap', 'OQMD_Energy_per_atom', 'OQMD_Formation_Enthalpy', 'OQMD_Volume_per_atom']\n",
      "property: aflow__ael_bulk_modulus_vrh\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 3 elements in the formula\n",
      "\n",
      "aflow__ael_bulk_modulus_vrh mae: 8.367\n",
      "property: aflow__ael_debye_temperature\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 3 elements in the formula\n",
      "\n",
      "aflow__ael_debye_temperature mae: 33.08\n",
      "property: aflow__ael_shear_modulus_vrh\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 3 elements in the formula\n",
      "\n",
      "aflow__ael_shear_modulus_vrh mae: 9.17\n",
      "property: aflow__agl_thermal_conductivity_300K\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 3 elements in the formula\n",
      "\n",
      "aflow__agl_thermal_conductivity_300K mae: 2.259\n",
      "property: aflow__agl_thermal_expansion_300K\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 3 elements in the formula\n",
      "\n",
      "aflow__agl_thermal_expansion_300K mae: 3.728e-06\n",
      "property: aflow__Egap\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 7 elements in the formula\n",
      "\n",
      "aflow__Egap mae: 0.3068\n",
      "property: aflow__energy_atom\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 7 elements in the formula\n",
      "\n",
      "aflow__energy_atom mae: 0.09513\n",
      "property: CritExam__Ed\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 8 elements in the formula\n",
      "\n",
      "CritExam__Ed mae: 0.06271\n",
      "property: CritExam__Ef\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 8 elements in the formula\n",
      "\n",
      "CritExam__Ef mae: 0.05876\n",
      "property: mp_bulk_modulus\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 5 elements in the formula\n",
      "\n",
      "mp_bulk_modulus mae: 10.85\n",
      "property: mp_elastic_anisotropy\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 5 elements in the formula\n",
      "\n",
      "mp_elastic_anisotropy mae: 8.262\n",
      "property: mp_e_hull\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 8 elements in the formula\n",
      "\n",
      "mp_e_hull mae: 0.08592\n",
      "property: mp_mu_b\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 8 elements in the formula\n",
      "\n",
      "mp_mu_b mae: 2.114\n",
      "property: mp_shear_modulus\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 5 elements in the formula\n",
      "\n",
      "mp_shear_modulus mae: 11.77\n",
      "property: OQMD_Bandgap\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 7 elements in the formula\n",
      "\n",
      "OQMD_Bandgap mae: 0.04427\n",
      "property: OQMD_Energy_per_atom\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 7 elements in the formula\n",
      "\n",
      "OQMD_Energy_per_atom mae: 0.03476\n",
      "property: OQMD_Formation_Enthalpy\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 7 elements in the formula\n",
      "\n",
      "OQMD_Formation_Enthalpy mae: 0.03278\n",
      "property: OQMD_Volume_per_atom\n",
      "=====================================================\n",
      "calculating test mae\n",
      "L-G-DCNN-v1\n",
      "loading data with up to 7 elements in the formula\n",
      "\n",
      "OQMD_Volume_per_atom mae: 0.298\n"
     ]
    }
   ],
   "source": [
    "lgdcnn_dir = r\"D:\\deep\\LGDCNN\"\n",
    "\n",
    "def load_model(model_name, mat_prop, classification, file_name, verbose=True):\n",
    "    # Load up a saved network.\n",
    "    model = Model(LGDCNN(compute_device=compute_device).to(compute_device),\n",
    "                  model_name=f'{mat_prop}', verbose=verbose)\n",
    "    model.load_network(model_name, f'{mat_prop}.pth') \n",
    "\n",
    "    # Check if classifcation task\n",
    "    if classification:\n",
    "        model.classification = True\n",
    "\n",
    "    # Load the data you want to predict with\n",
    "    data = os.path.join(lgdcnn_dir,\"data\",\"benchmark_data\",mat_prop,file_name)\n",
    "    # data is reloaded to model.data_loader\n",
    "    model.load_data(data, batch_size=2**9, train=False)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_results(model):\n",
    "    output = model.predict(model.data_loader)  # predict the data saved here\n",
    "    return model, output\n",
    "\n",
    "\n",
    "def save_results(model_name, mat_prop, classification, file_name, verbose=True):\n",
    "    model = load_model(model_name, mat_prop, classification, file_name, verbose=verbose)\n",
    "    model, output = get_results(model)\n",
    "\n",
    "    # Get appropriate metrics for saving to csv\n",
    "    if model.classification:\n",
    "        auc = roc_auc_score(output[0], output[1])\n",
    "        print(f'\\n{mat_prop} ROC AUC: {auc:0.4f}')\n",
    "    else:\n",
    "        mae = np.abs(output[0] - output[1]).mean()\n",
    "        print(f'\\n{mat_prop} mae: {mae:0.4g}')\n",
    "\n",
    "    return model, mae\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # choose model\n",
    "    model_name = \"L-G-DCNN-v1\"\n",
    "    # To construct the path of the benchmark_data folder\n",
    "    benchmark_data_dir = os.path.join(lgdcnn_dir,\"data\",\"benchmark_data\")\n",
    "    mat_props = os.listdir(benchmark_data_dir)\n",
    "    classification_list = []\n",
    "    print(f'training: {mat_props}')\n",
    "    for mat_prop in mat_props:\n",
    "        classification = False\n",
    "        if mat_prop in classification_list:\n",
    "            classification = True\n",
    "        print(f'property: {mat_prop}')\n",
    "        print('=====================================================')\n",
    "        print('calculating test mae')\n",
    "        model_test, t_mae = save_results(model_name, mat_prop, classification,\n",
    "                                         'test.csv', verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取mp数据库中多元相图的形成能数据代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "# from pymatgen.analysis.phase_diagram import PhaseDiagram, PDPlotter\n",
    "import pandas as pdd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = MPRester('kQD0riCq7tpsdbWK')\n",
    "# entries = a.get_entries_in_chemsys(['Li', 'Mo', 'O','P'])\n",
    "\n",
    "#With entries, you can do many sophisticated analyses, like creating phase diagrams.\n",
    "# pd = PhaseDiagram(entries)\n",
    "\n",
    "#Let's show all phases, including unstable ones\n",
    "# plotter = PDPlotter(pd, show_unstable=0.2,)\n",
    "# plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MPRester('kQD0riCq7tpsdbWK')\n",
    "entries = a.get_entries_in_chemsys(['Ga', 'O'])\n",
    "\n",
    "mat_id = [i.entry_id for i in entries]\n",
    "com = [i.composition.reduced_formula for i in entries]\n",
    "all_data = []\n",
    "for i in mat_id:\n",
    "    data = a.query(criteria={\"task_id\": i}, properties=[\"formation_energy_per_atom\",\"magnetism.total_magnetization_normalized_formula_units\",\"e_above_hull\",\"elasticity.K_VRH\",\"elasticity.G_VRH\",\"band_gap\",\"diel.n\"])\n",
    "    all_data.append(data)\n",
    "\n",
    "e_formation = [i[0]['formation_energy_per_atom'] for i in all_data]\n",
    "total_magnetization = [i[0]['magnetism.total_magnetization_normalized_formula_units'] for i in all_data]\n",
    "e_above_hull = [i[0]['e_above_hull'] for i in all_data]\n",
    "Bulk_Modulus = [i[0]['elasticity.K_VRH'] for i in all_data]\n",
    "Shear_Modulus = [i[0]['elasticity.G_VRH'] for i in all_data]\n",
    "band_gap = [i[0]['band_gap'] for i in all_data]\n",
    "dielectric = [i[0]['diel.n'] for i in all_data]\n",
    "\n",
    "df_all = pdd.DataFrame(dict(zip(['material_id', 'formula', 'formation_energy_per_atom', 'magnetism.total_magnetization_normalized_formula_units','e_above_hull','elasticity.K_VRH','elasticity.G_VRH','band_gap','diel.n'],\n",
    "                               [mat_id, com, e_formation, total_magnetization, e_above_hull, Bulk_Modulus, Shear_Modulus, band_gap, dielectric])))\n",
    "\n",
    "data_dir = rf'D:\\deep\\CrabNet\\data\\application\\MP'\n",
    "seed_ = 'Ga_O_all.csv'  \n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_all.to_csv(rf'{data_dir}/{seed_}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This initializes the REST adaptor. You may need to put your own API key in as an arg.\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "from pymatgen.analysis.phase_diagram import PhaseDiagram, PDPlotter\n",
    "import pandas as pdd\n",
    "import os\n",
    "a = MPRester(api_key='kQD0riCq7tpsdbWK') # y9WVXfllm2gQdZ6D4TCsE9w9gWX5VL8r   kQD0riCq7tpsdbWK\n",
    "\n",
    "entries = a.get_entries_in_chemsys(['Al', 'O'])\n",
    "\n",
    "#With entries, you can do many sophisticated analyses, like creating phase diagrams.\n",
    "# pd = PhaseDiagram(entries)\n",
    "\n",
    "#Let's show all phases, including unstable ones\n",
    "# plotter = PDPlotter(pd, show_unstable=0.2,)\n",
    "# plotter.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diel.n\n",
    "com = [i.composition.reduced_formula for i in entries]\n",
    "\n",
    "diel_m = [a.query(criteria={\"task_id\": i.entry_id}, properties=[\"diel.n\"])[0]['diel.n'] for i in entries]\n",
    "df_shear = pdd.DataFrame(dict(zip(['formula','target'],[ com, diel_m])))\n",
    "\n",
    "data_dir1 = rf'D:\\deep\\CrabNet\\data\\application\\MP_dielectric'\n",
    "seed_1 = 'Mn_O_mp_dielectric.csv'  \n",
    "os.makedirs(data_dir1, exist_ok=True)\n",
    "df_shear.to_csv(rf'{data_dir1}/{seed_1}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = [i.composition.reduced_formula for i in entries]\n",
    "\n",
    "# mag = [a.query(criteria={\"task_id\": i.entry_id}, properties=[\"elasticity.K_VRH\"])[0]['elasticity.K_VRH'] for i in entries]\n",
    "# df_ti = pdd.DataFrame(dict(zip(['formula','target'],[ com, mag])))\n",
    "\n",
    "shear_m = [a.query(criteria={\"task_id\": i.entry_id}, properties=[\"elasticity.G_VRH\"])[0]['elasticity.G_VRH'] for i in entries]\n",
    "df_shear = pdd.DataFrame(dict(zip(['formula','target'],[ com, shear_m])))\n",
    "\n",
    "# data_dir = rf'D:\\deep\\CrabNet\\data\\application\\MP_Bulk_Modulus'\n",
    "# seed_ = 'Al_O_mp_bulk_modulus.csv'  \n",
    "# os.makedirs(data_dir, exist_ok=True)\n",
    "# df_ti.to_csv(rf'{data_dir}/{seed_}', index=False)\n",
    "\n",
    "data_dir1 = rf'D:\\deep\\CrabNet\\data\\application\\MP_Shear_Modulus'\n",
    "seed_1 = 'Si_O_mp_shear_modulus.csv'  \n",
    "os.makedirs(data_dir1, exist_ok=True)\n",
    "df_shear.to_csv(rf'{data_dir1}/{seed_1}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get_data( entries[20].entry_id, data_type=\"vasp\", prop=\"e_above_hull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'diel.n': 1.4659358785431238}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = a.query(criteria={\"task_id\": entries[24].entry_id}, properties=[\"diel.n\"])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2020_09_08'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.get_database_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.50449542"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0].energy_per_atom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_e = [pd.get_form_energy_per_atom(i) for i in entries]\n",
    "# com = [i.composition.reduced_formula for i in entries]\n",
    "# e_each_atom = [i.energy_per_atom for i in entries]\n",
    "# mat_id = [i.entry_id for i in entries]\n",
    "\n",
    "# df_ti = pdd.DataFrame(dict(zip(['material_id','formula','form_energy_per_atom', 'energy_per_atom'],\n",
    "# [mat_id, com, delta_e, e_each_atom])))\n",
    "\n",
    "# data_dir = rf'D:\\deep\\CrabNet\\data\\application\\MP_e_form'\n",
    "# seed_ = 'Mn_O_all.csv'  \n",
    "# os.makedirs(data_dir, exist_ok=True)\n",
    "# df_ti.to_csv(rf'{data_dir}/{seed_}', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 得到 MP数据库中几个关键数据 并保存为.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymatgen.ext.matproj import MPRester\n",
    "a = MPRester(api_key='kQD0riCq7tpsdbWK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_id = [i.entry_id for i in entries]\n",
    "com = [i.composition.reduced_formula for i in entries]\n",
    "all_data = []\n",
    "for i in mat_id:\n",
    "    data = a.query(criteria={\"task_id\": i}, properties=[\"formation_energy_per_atom\", \"magnetism.total_magnetization_normalized_formula_units\",\"e_above_hull\",\"elasticity.K_VRH\",\"elasticity.G_VRH\",\"band_gap\",\"diel.n\"])\n",
    "    all_data.append(data)\n",
    "\n",
    "\n",
    "magnetization_unit = [i[0]['magnetism.total_magnetization'] for i in all_data]\n",
    "e_above_hull = [i[0]['e_above_hull'] for i in all_data]\n",
    "Bulk_Modulus = [i[0]['elasticity.K_VRH'] for i in all_data]\n",
    "Shear_Modulus = [i[0]['elasticity.G_VRH'] for i in all_data]\n",
    "band_gap = [i[0]['band_gap'] for i in all_data]\n",
    "dielectric = [i[0]['diel.n'] for i in all_data]\n",
    "\n",
    "df_all = pdd.DataFrame(dict(zip(['material_id','formula','magnetism.total_magnetization_normalized_formula_units','e_above_hull','elasticity.K_VRH','elasticity.G_VRH','band_gap','diel.n'],\n",
    "                               [mat_id, com, magnetization_unit, e_above_hull, Bulk_Modulus, Shear_Modulus, band_gap, dielectric])))\n",
    "\n",
    "data_dir = rf'D:\\deep\\CrabNet\\data\\application\\MP'\n",
    "seed_ = 'Li_B_O_all.csv'  \n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_all.to_csv(rf'{data_dir}/{seed_}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'magnetism.total_magnetization': 2.184898,\n",
       "  'e_above_hull': 0.6572110503448272,\n",
       "  'elasticity.K_VRH': None,\n",
       "  'elasticity.G_VRH': None,\n",
       "  'band_gap': 0.0,\n",
       "  'diel.n': None}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'total_magnetization': 1.092449}]\n"
     ]
    }
   ],
   "source": [
    "# \"G_VRH\":Shear Modulus, \"K_VRH\":Bulk Modulus\n",
    "data = m.query(criteria={\"task_id\": entries[0].entry_id}, properties=[\"total_magnetization\"])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'diel.n': None}]\n"
     ]
    }
   ],
   "source": [
    "data = m.query(criteria={\"task_id\": entries[0].entry_id}, properties=[\"diel.n\"])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mp-1057139'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[0].entry_id"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train val test 拆分数据集代码"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OQMD band gap train val test 数据集拆分为10份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取所有的OQMD数据包括 val train and test\n",
    "X_d_test = pd.read_csv(r'D:\\deep\\CrabNet\\data\\benchmark_data\\OQMD_Bandgap\\test.csv')\n",
    "X_d_train = pd.read_csv(r'D:\\deep\\CrabNet\\data\\benchmark_data\\OQMD_Bandgap\\train.csv')\n",
    "X_d_val = pd.read_csv(r'D:\\deep\\CrabNet\\data\\benchmark_data\\OQMD_Bandgap\\val.csv')\n",
    "data_dir = f'data/OQMD/' \n",
    "seed_f_val = 'OQMD_Band_gap_all.csv'\n",
    "\n",
    "X_d_test.to_csv(f'{data_dir}/{seed_f_val}',index=False)\n",
    "X_d_train.to_csv(f'{data_dir}/{seed_f_val}', index=False, header=False, mode='a+')\n",
    "X_d_val.to_csv(f'{data_dir}/{seed_f_val}', index=False, header=False, mode='a+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'D:\\deep\\CrabNet\\data\\OQMD\\OQMD_Band_gap_all.csv')\n",
    "df = pd.read_csv(r'D:\\deep\\CrabNet\\data\\OQMD\\0005\\gap_0005.csv')\n",
    "df_gap = df['target'].values\n",
    "df_formula = df['formula'].values\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1, test_size=0.1)\n",
    "for train_index, test_index in rs.split(df_gap):\n",
    "    delta_e_train = df_gap[train_index]\n",
    "    delta_e_test = df_gap[test_index]\n",
    "\n",
    "    com_train = df_formula[train_index]\n",
    "    com_test = df_formula[test_index]\n",
    "\n",
    "df_test = pd.DataFrame(dict(zip(['formula', 'target'],[com_test, delta_e_test])))\n",
    "data_dir = f'data/OQMD/0005' \n",
    "name = 'test.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_test.to_csv(f'{data_dir}/{name}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs1 = ShuffleSplit(n_splits=1, test_size=0.111)\n",
    "\n",
    "for train_index, val_index in rs1.split(delta_e_train):\n",
    "    train = delta_e_train[train_index]\n",
    "    val = delta_e_train[val_index]\n",
    "\n",
    "    composition_train = com_train[train_index]\n",
    "    composition_val = com_train[val_index]\n",
    "\n",
    "df_train = pd.DataFrame(dict(zip(['formula', 'target'],[composition_train, train])))\n",
    "name1 = 'train.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_train.to_csv(f'{data_dir}/{name1}', index=False)\n",
    "\n",
    "df_val = pd.DataFrame(dict(zip(['formula', 'target'],[composition_val, val])))\n",
    "name2 = 'val.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_val.to_csv(f'{data_dir}/{name2}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(r'D:\\deep\\CrabNet\\data\\OQMD\\OQMD_Band_gap_all.csv')\n",
    "df = pd.read_csv(r'D:\\deep\\CrabNet\\data\\application\\transfer\\mp-non-metals.csv')\n",
    "df_gap = df['target'].values\n",
    "df_formula = df['formula'].values\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, test_index in rs.split(df_gap):\n",
    "    delta_e_train = df_gap[train_index]\n",
    "    delta_e_test = df_gap[test_index]\n",
    "\n",
    "    com_train = df_formula[train_index]\n",
    "    com_test = df_formula[test_index]\n",
    "\n",
    "df_test = pd.DataFrame(dict(zip(['formula', 'target'],[com_test, delta_e_test])))\n",
    "data_dir = f'data/application/transfer' \n",
    "name = 'test.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_test.to_csv(f'{data_dir}/{name}', index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs1 = ShuffleSplit(n_splits=1, test_size=0.1)\n",
    "\n",
    "for train_index, val_index in rs1.split(delta_e_train):\n",
    "    train = delta_e_train[train_index]\n",
    "    val = delta_e_train[val_index]\n",
    "\n",
    "    composition_train = com_train[train_index]\n",
    "    composition_val = com_train[val_index]\n",
    "\n",
    "df_train = pd.DataFrame(dict(zip(['formula', 'target'],[composition_train, train])))\n",
    "name1 = 'train.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_train.to_csv(f'{data_dir}/{name1}', index=False)\n",
    "\n",
    "df_val = pd.DataFrame(dict(zip(['formula', 'target'],[composition_val, val])))\n",
    "name2 = 'val.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_val.to_csv(f'{data_dir}/{name2}', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oqmd_all-22Mar18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(r'D:\\deep\\CrabNet\\data\\application\\oqmd_all-22Mar18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_e_convert_to_float(data):\n",
    "    return float(data.split('  ')[-2].strip())\n",
    "\n",
    "def com_convert_to_float(data):\n",
    "    return data.split('  ')[0].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_select_delta_e = X_df['comp energy_pa volume_pa magmom_pa bandgap delta_e stability'].apply(lambda row: delta_e_convert_to_float(row))\n",
    "df_select_com = X_df['comp energy_pa volume_pa magmom_pa bandgap delta_e stability'].apply(lambda row: com_convert_to_float(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(620196,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = ShuffleSplit(n_splits=1, test_size=0.15)\n",
    "\n",
    "for train_index, test_index in rs.split(df_select_delta_e):\n",
    "    delta_e_train = df_select_delta_e[train_index]\n",
    "    delta_e_test = df_select_delta_e[test_index]\n",
    "\n",
    "    com_train = df_select_com[train_index]\n",
    "    com_test = df_select_com[test_index]\n",
    "\n",
    "delta_e_col = X_df.columns.values.tolist()[0].split(' ')[-2]\n",
    "com_col = X_df.columns.values.tolist()[0].split(' ')[0]\n",
    "\n",
    "df_test = pd.DataFrame(dict(zip([com_col, delta_e_col],[com_test, delta_e_test])))\n",
    "seed_f_test = 'oqmd_delta_e_test.csv'\n",
    "data_dir = f'data/application' \n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_test = df_test.rename(columns={com_col:'formula',delta_e_col:'target'})\n",
    "df_test.to_csv(f'{data_dir}/{seed_f_test}', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs1 = ShuffleSplit(n_splits=1, test_size=0.15)\n",
    "\n",
    "delta_e_train = delta_e_train.reset_index(drop=True)\n",
    "com_train = com_train.reset_index(drop=True)\n",
    "for train_index, val_index in rs1.split(delta_e_train):\n",
    "    train = delta_e_train[train_index]\n",
    "    val = delta_e_train[val_index]\n",
    "\n",
    "    composition_train = com_train[train_index]\n",
    "    composition_val = com_train[val_index]\n",
    "\n",
    "df_train = pd.DataFrame(dict(zip([com_col, delta_e_col],[composition_train, train])))\n",
    "seed_f_train = 'oqmd_delta_e_train.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_train = df_train.rename(columns={com_col:'formula',delta_e_col:'target'})\n",
    "df_train.to_csv(f'{data_dir}/{seed_f_train}', index=False)\n",
    "\n",
    "df_val = pd.DataFrame(dict(zip([com_col, delta_e_col],[composition_val, val])))\n",
    "seed_f_val = 'oqmd_delta_e_val.csv'\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "df_val = df_val.rename(columns={com_col:'formula',delta_e_col:'target'})\n",
    "df_val.to_csv(f'{data_dir}/{seed_f_val}', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7dd5d76405b906035e1d1a24c7f24088f68ab8fc773386bbbd9b8e7c7c6d48a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
